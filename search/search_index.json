{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is a wiki where I store useful information that I find and links using MkDocs . The format and process to generate the wiki was taken from Lyz-code's blue book . Thanks very much Lyz-code!","title":"Introduction"},{"location":"contact/","text":"Create an issue in the Github if you wish to reach out.","title":"Contact"},{"location":"emojis/","text":"Curated list of emojis to copy paste. Angry \u00b6 (\u0482\u2323\u0300_\u2323\u0301) ( >\u0434<) \u0295\u2022\u0300o\u2022\u0301\u0294 \u30fd(\u2267\u0414\u2266)\u30ce \u1559(\u21c0\u2038\u21bc\u2036)\u1557 \u0669(\u256c\u0298\u76ca\u0298\u256c)\u06f6 Annoyed \u00b6 (>_<) Awesome \u00b6 ( \u00b7_\u00b7) ( \u00b7_\u00b7) --\u25a0-\u25a0 ( \u00b7_\u00b7)--\u25a0-\u25a0 (-\u25a0_\u25a0) YEAAAAAAAAAAAAAAAAAAAAAHHHHHHHHHHHH Conforting \u00b6 (\uff4f\u30fb_\u30fb)\u30ce\u201d(\u1d17_ \u1d17\u3002) Congratulations \u00b6 ( \u141b )\u0648 \uff3c\\ \u0669( \u141b )\u0648 /\uff0f Crying \u00b6 (\u2565\ufe4f\u2565) Excited \u00b6 (((o(*\uff9f\u25bd\uff9f*)o))) o(\u2267\u2207\u2266o) Dance \u00b6 (~\u203e\u25bf\u203e)~ ~(\u203e\u25bf\u203e)~ ~(\u203e\u25bf\u203e~) \u250c(\u30fb\u3002\u30fb)\u2518 \u266a \u2514(\u30fb\u3002\u30fb)\u2510 \u266a \u250c(\u30fb\u3002\u30fb)\u2518 \u01aa(\u02d8\u2323\u02d8)\u2510 \u01aa(\u02d8\u2323\u02d8)\u0283 \u250c(\u02d8\u2323\u02d8)\u0283 (>'-')> <('-'<) ^('-')^ v('-')v (>'-')> (^-^) Happy \u00b6 \u1555( \u141b )\u1557 \u0295\u2022\u1d25\u2022\u0294 (\u2022\u203f\u2022) (\u25e1\u203f\u25e1\u273f) (\u273f\u25e0\u203f\u25e0) \u266a(\u0e51\u1d16\u25e1\u1d16\u0e51)\u266a Kisses \u00b6 (\u3065\uffe3 \u00b3\uffe3)\u3065 ( \u02d8 \u00b3\u02d8)\u2665 Love \u00b6 \u2764 Pride \u00b6 <(\uffe3\uff3e\uffe3)> Relax \u00b6 _\u3078__(\u203e\u25e1\u25dd )> Sad \u00b6 \uff61\uff9f(*\u00b4\u25a1`)\uff9f\uff61 (\u25de\u2038\u25df\uff1b) Scared \u00b6 \u30fd(\uff9f\u0414\uff9f)\uff89 \u30fd\u3014\uff9f\u0414\uff9f\u3015\u4e3f Sleepy \u00b6 (\u1d17\u02f3\u1d17) Smug \u00b6 \uff08\uffe3\uff5e\uffe3\uff09 Whyyyy? \u00b6 (/\uff9f\u0414\uff9f)/ Surprised \u00b6 (\\_/) (O.o) (> <) (\u2299_\u2609) (\u00ac\u00ba-\u00b0)\u00ac (\u2609_\u2609) (\u2022 \u0325\u0306\u2006\u2022) \u00af\\(\u00b0_o)/\u00af (\u30fb0\u30fb\u3002(\u30fb-\u30fb\u3002(\u30fb0\u30fb\u3002(\u30fb-\u30fb\u3002) (*\uff9f\u25ef\uff9f*) Who cares \u00b6 \u00af\\_(\u30c4)_/\u00af WTF \u00b6 (\u256f\u00b0\u25a1\u00b0)\u256f \u253b\u2501\u253b \u30d8\uff08\u3002\u25a1\u00b0\uff09\u30d8 Links \u00b6 Japanese Emoticons","title":"Emojis"},{"location":"emojis/#angry","text":"(\u0482\u2323\u0300_\u2323\u0301) ( >\u0434<) \u0295\u2022\u0300o\u2022\u0301\u0294 \u30fd(\u2267\u0414\u2266)\u30ce \u1559(\u21c0\u2038\u21bc\u2036)\u1557 \u0669(\u256c\u0298\u76ca\u0298\u256c)\u06f6","title":"Angry"},{"location":"emojis/#annoyed","text":"(>_<)","title":"Annoyed"},{"location":"emojis/#awesome","text":"( \u00b7_\u00b7) ( \u00b7_\u00b7) --\u25a0-\u25a0 ( \u00b7_\u00b7)--\u25a0-\u25a0 (-\u25a0_\u25a0) YEAAAAAAAAAAAAAAAAAAAAAHHHHHHHHHHHH","title":"Awesome"},{"location":"emojis/#conforting","text":"(\uff4f\u30fb_\u30fb)\u30ce\u201d(\u1d17_ \u1d17\u3002)","title":"Conforting"},{"location":"emojis/#congratulations","text":"( \u141b )\u0648 \uff3c\\ \u0669( \u141b )\u0648 /\uff0f","title":"Congratulations"},{"location":"emojis/#crying","text":"(\u2565\ufe4f\u2565)","title":"Crying"},{"location":"emojis/#excited","text":"(((o(*\uff9f\u25bd\uff9f*)o))) o(\u2267\u2207\u2266o)","title":"Excited"},{"location":"emojis/#dance","text":"(~\u203e\u25bf\u203e)~ ~(\u203e\u25bf\u203e)~ ~(\u203e\u25bf\u203e~) \u250c(\u30fb\u3002\u30fb)\u2518 \u266a \u2514(\u30fb\u3002\u30fb)\u2510 \u266a \u250c(\u30fb\u3002\u30fb)\u2518 \u01aa(\u02d8\u2323\u02d8)\u2510 \u01aa(\u02d8\u2323\u02d8)\u0283 \u250c(\u02d8\u2323\u02d8)\u0283 (>'-')> <('-'<) ^('-')^ v('-')v (>'-')> (^-^)","title":"Dance"},{"location":"emojis/#happy","text":"\u1555( \u141b )\u1557 \u0295\u2022\u1d25\u2022\u0294 (\u2022\u203f\u2022) (\u25e1\u203f\u25e1\u273f) (\u273f\u25e0\u203f\u25e0) \u266a(\u0e51\u1d16\u25e1\u1d16\u0e51)\u266a","title":"Happy"},{"location":"emojis/#kisses","text":"(\u3065\uffe3 \u00b3\uffe3)\u3065 ( \u02d8 \u00b3\u02d8)\u2665","title":"Kisses"},{"location":"emojis/#love","text":"\u2764","title":"Love"},{"location":"emojis/#pride","text":"<(\uffe3\uff3e\uffe3)>","title":"Pride"},{"location":"emojis/#relax","text":"_\u3078__(\u203e\u25e1\u25dd )>","title":"Relax"},{"location":"emojis/#sad","text":"\uff61\uff9f(*\u00b4\u25a1`)\uff9f\uff61 (\u25de\u2038\u25df\uff1b)","title":"Sad"},{"location":"emojis/#scared","text":"\u30fd(\uff9f\u0414\uff9f)\uff89 \u30fd\u3014\uff9f\u0414\uff9f\u3015\u4e3f","title":"Scared"},{"location":"emojis/#sleepy","text":"(\u1d17\u02f3\u1d17)","title":"Sleepy"},{"location":"emojis/#smug","text":"\uff08\uffe3\uff5e\uffe3\uff09","title":"Smug"},{"location":"emojis/#whyyyy","text":"(/\uff9f\u0414\uff9f)/","title":"Whyyyy?"},{"location":"emojis/#surprised","text":"(\\_/) (O.o) (> <) (\u2299_\u2609) (\u00ac\u00ba-\u00b0)\u00ac (\u2609_\u2609) (\u2022 \u0325\u0306\u2006\u2022) \u00af\\(\u00b0_o)/\u00af (\u30fb0\u30fb\u3002(\u30fb-\u30fb\u3002(\u30fb0\u30fb\u3002(\u30fb-\u30fb\u3002) (*\uff9f\u25ef\uff9f*)","title":"Surprised"},{"location":"emojis/#who-cares","text":"\u00af\\_(\u30c4)_/\u00af","title":"Who cares"},{"location":"emojis/#wtf","text":"(\u256f\u00b0\u25a1\u00b0)\u256f \u253b\u2501\u253b \u30d8\uff08\u3002\u25a1\u00b0\uff09\u30d8","title":"WTF"},{"location":"emojis/#links","text":"Japanese Emoticons","title":"Links"},{"location":"coding/coding/","text":"Coding notes \u00b6","title":"Coding"},{"location":"coding/coding/#coding-notes","text":"","title":"Coding notes"},{"location":"coding/git/","text":"Useful commands \u00b6 Clone a repo with limited history and specific branch \u00b6 git clone --depth 10 --single-branch --branch <mybranch> <therepo>","title":"Git"},{"location":"coding/git/#useful-commands","text":"","title":"Useful commands"},{"location":"coding/git/#clone-a-repo-with-limited-history-and-specific-branch","text":"git clone --depth 10 --single-branch --branch <mybranch> <therepo>","title":"Clone a repo with limited history and specific branch"},{"location":"coding/jvm/jfr/","text":"Flight Recorder Info \u00b6 The info below was testing specifically for Java version 8. As of Java version 11, the Flight recorder is now part of the standard OpenJDK and does not require enabling of commerical features. This also means that it can be used in production. As of OpenJDK 8u262 JFR is now also available. Enabling JVM app for Flight Recorder \u00b6 Oracle JVM \u00b6 For Oracle there are specific flags that need to be set for the app. Obviously the changes below are only allowed on non-production systems unless you have paid for licenses from Oracle. -XX:+UnlockCommercialFeatures -XX:+FlightRecorder It is also recommended to enable the two flags below. Out of the box the method profiler will use safepoint boundaries when profiling methods, which may skew results. When enabling the flags below when necessary, you will get more accurate profiling results on where the time is spent in your app. This is why Flight recorder is preferred over other profilers such as YourKit, VisualVM. -XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints Capturing a recording \u00b6 Flight Recorder - Start with app \u00b6 -XX:StartFlightRecording=duration=20s,delay=5s,settings=profile,filename=recording.jfr Flight Recorder - Start Recording on running JVM \u00b6 Start a recording with a time limit, specifying location to save to and compression. jcmd <process id> JFR.start name=Test-01 filename=/app/record-test-01.jfr settings=default-with-alloc duration=30s stackdepth=1024 Flight Recorder - Start recording with no duration defined \u00b6 Start a recording without a time limit, a future command will be executed to dump manually to a file. jcmd <process id> JFR.start name=Test-07 settings=profile Flight Recorder - Dump recording that is running \u00b6 Dump the recording when enough data has been captured. jcmd <process id> JFR.dump name=Test-08 filename=/app/test-08.jfr Flight Recorder - Enable Allocations capture \u00b6 Copy default.jfr and edit the file in /jre/lib/jfr/ Edit the file (or better yet a copy of it) and change the following to enable allocation tracking. The profile.jfr also includes allocation capture. <flag name= \"allocation-profiling-enabled\" label= \"Allocation Profiling\" > true </flag> <event path= \"java/object_alloc_in_new_TLAB\" > <setting name= \"enabled\" control= \"allocation-profiling-enabled\" > true </setting> <setting name= \"stackTrace\" > true </setting> </event> <event path= \"java/object_alloc_outside_TLAB\" > <setting name= \"enabled\" control= \"allocation-profiling-enabled\" > true </setting> <setting name= \"stackTrace\" > true </setting> </event> Links \u00b6 https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/","title":"Java Flight Recorder"},{"location":"coding/jvm/jfr/#flight-recorder-info","text":"The info below was testing specifically for Java version 8. As of Java version 11, the Flight recorder is now part of the standard OpenJDK and does not require enabling of commerical features. This also means that it can be used in production. As of OpenJDK 8u262 JFR is now also available.","title":"Flight Recorder Info"},{"location":"coding/jvm/jfr/#enabling-jvm-app-for-flight-recorder","text":"","title":"Enabling JVM app for Flight Recorder"},{"location":"coding/jvm/jfr/#oracle-jvm","text":"For Oracle there are specific flags that need to be set for the app. Obviously the changes below are only allowed on non-production systems unless you have paid for licenses from Oracle. -XX:+UnlockCommercialFeatures -XX:+FlightRecorder It is also recommended to enable the two flags below. Out of the box the method profiler will use safepoint boundaries when profiling methods, which may skew results. When enabling the flags below when necessary, you will get more accurate profiling results on where the time is spent in your app. This is why Flight recorder is preferred over other profilers such as YourKit, VisualVM. -XX:+UnlockDiagnosticVMOptions -XX:+DebugNonSafepoints","title":"Oracle JVM"},{"location":"coding/jvm/jfr/#capturing-a-recording","text":"","title":"Capturing a recording"},{"location":"coding/jvm/jfr/#flight-recorder-start-with-app","text":"-XX:StartFlightRecording=duration=20s,delay=5s,settings=profile,filename=recording.jfr","title":"Flight Recorder - Start with app"},{"location":"coding/jvm/jfr/#flight-recorder-start-recording-on-running-jvm","text":"Start a recording with a time limit, specifying location to save to and compression. jcmd <process id> JFR.start name=Test-01 filename=/app/record-test-01.jfr settings=default-with-alloc duration=30s stackdepth=1024","title":"Flight Recorder - Start Recording on running JVM"},{"location":"coding/jvm/jfr/#flight-recorder-start-recording-with-no-duration-defined","text":"Start a recording without a time limit, a future command will be executed to dump manually to a file. jcmd <process id> JFR.start name=Test-07 settings=profile","title":"Flight Recorder - Start recording with no duration defined"},{"location":"coding/jvm/jfr/#flight-recorder-dump-recording-that-is-running","text":"Dump the recording when enough data has been captured. jcmd <process id> JFR.dump name=Test-08 filename=/app/test-08.jfr","title":"Flight Recorder - Dump recording that is running"},{"location":"coding/jvm/jfr/#flight-recorder-enable-allocations-capture","text":"Copy default.jfr and edit the file in /jre/lib/jfr/ Edit the file (or better yet a copy of it) and change the following to enable allocation tracking. The profile.jfr also includes allocation capture. <flag name= \"allocation-profiling-enabled\" label= \"Allocation Profiling\" > true </flag> <event path= \"java/object_alloc_in_new_TLAB\" > <setting name= \"enabled\" control= \"allocation-profiling-enabled\" > true </setting> <setting name= \"stackTrace\" > true </setting> </event> <event path= \"java/object_alloc_outside_TLAB\" > <setting name= \"enabled\" control= \"allocation-profiling-enabled\" > true </setting> <setting name= \"stackTrace\" > true </setting> </event>","title":"Flight Recorder - Enable Allocations capture"},{"location":"coding/jvm/jfr/#links","text":"https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/","title":"Links"},{"location":"coding/jvm/jvm-flags/","text":"This page contains useful JVM flags and information on setting JVM flags. Show me current flag settings \u00b6 java -XX:+PrintFlagsFinal -version Will output the current config which you can pipe or grep on to your heart's content.","title":"JVM Flags"},{"location":"coding/jvm/jvm-flags/#show-me-current-flag-settings","text":"java -XX:+PrintFlagsFinal -version Will output the current config which you can pipe or grep on to your heart's content.","title":"Show me current flag settings"},{"location":"coding/jvm/jvm-troubleshooting/","text":"JVM Troubleshooting \u00b6 This lists useful commands and options for troubleshooting performance or other issues with the JVM. Find JVMs available to connect through jcmd \u00b6 jcmd This will list all the JVM processes it can find with their pids. List all commands available via jcmd in the JVM \u00b6 jcmd <pid> help This will for the particular JVM output the commands available. Capturing a heap dump from JVM \u00b6 Take a dump of all objects, not just live objects in the binary format. This does not force a full GC and may include dead objects. jmap -dump:format = b,file = <filename.hprof> <pid> Heap dump with forced full GC before dump: jmap -dump:live,format = b,file = <filename.hprof> <pid> https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jmap.html Using jcmd (note does not seem to support live objects only) jcmd <pid> GC.heap_dump filename = <file> Heap Histogram \u00b6 Live objects without forcing a full GC. jcmd <pid> GC.class_histogram Includes dead objects. jmap -histo <pid> Forces a full gc before outputting the histogram. jmap -histo:live <pid> Dump Native Memory Summary \u00b6 Must be enabled with JVM flag -XX:NativeMemoryTracking=summary Dumps a summary of the usage of the native memory by the JVM. jcmd <pid> VM.native_memory summary You can also take a baseline and do a comparison: jcmd <pid> VM.native_memory baseline You can then compare the baseline to the current: jcmd <pid> VM.native_memory summary.diff Dump class stats (>=J8) \u00b6 Must be enabled with JVM flag -XX:+UnlockDiagnosticVMOptions jcmd <pid> GC.class_stats","title":"JVM Troubleshooting"},{"location":"coding/jvm/jvm-troubleshooting/#jvm-troubleshooting","text":"This lists useful commands and options for troubleshooting performance or other issues with the JVM.","title":"JVM Troubleshooting"},{"location":"coding/jvm/jvm-troubleshooting/#find-jvms-available-to-connect-through-jcmd","text":"jcmd This will list all the JVM processes it can find with their pids.","title":"Find JVMs available to connect through jcmd"},{"location":"coding/jvm/jvm-troubleshooting/#list-all-commands-available-via-jcmd-in-the-jvm","text":"jcmd <pid> help This will for the particular JVM output the commands available.","title":"List all commands available via jcmd in the JVM"},{"location":"coding/jvm/jvm-troubleshooting/#capturing-a-heap-dump-from-jvm","text":"Take a dump of all objects, not just live objects in the binary format. This does not force a full GC and may include dead objects. jmap -dump:format = b,file = <filename.hprof> <pid> Heap dump with forced full GC before dump: jmap -dump:live,format = b,file = <filename.hprof> <pid> https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jmap.html Using jcmd (note does not seem to support live objects only) jcmd <pid> GC.heap_dump filename = <file>","title":"Capturing a heap dump from JVM"},{"location":"coding/jvm/jvm-troubleshooting/#heap-histogram","text":"Live objects without forcing a full GC. jcmd <pid> GC.class_histogram Includes dead objects. jmap -histo <pid> Forces a full gc before outputting the histogram. jmap -histo:live <pid>","title":"Heap Histogram"},{"location":"coding/jvm/jvm-troubleshooting/#dump-native-memory-summary","text":"Must be enabled with JVM flag -XX:NativeMemoryTracking=summary Dumps a summary of the usage of the native memory by the JVM. jcmd <pid> VM.native_memory summary You can also take a baseline and do a comparison: jcmd <pid> VM.native_memory baseline You can then compare the baseline to the current: jcmd <pid> VM.native_memory summary.diff","title":"Dump Native Memory Summary"},{"location":"coding/jvm/jvm-troubleshooting/#dump-class-stats-j8","text":"Must be enabled with JVM flag -XX:+UnlockDiagnosticVMOptions jcmd <pid> GC.class_stats","title":"Dump class stats (&gt;=J8)"},{"location":"coding/jvm/jvm/","text":"This page contains links for information on the JVM. Child pages \u00b6 JVM Flags JVM Troublehsooting Java native memory \u00b6 Stats were added in Java 8 when the permgen data was moved off heap. Enabled by setting the option: -XX:NativeMemoryTracking=off|summary|details If you enable the summary or detailed information it is then possible to capture the stats using jcmd: jcmd <pid> VM.native_memory_summary It is also possible to set a baseline and then produce a diff using jcmd Start app and capture baseline jcmd <pid> VM.native_memory baseline Then you can produce a diff jcmd <pid> VM.native_memory summary.diff You can access the detailed information using jcmd again: jcmd <pid> VM.native_memory detail Java object layout \u00b6 Provides a good guide to the size of the object header in Java and what it is made up of, for 64bit (compressed oops on and off) and 32 bit JVM. https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c Excellent guide to memory layout: http://psy-lob-saw.blogspot.com/2013/05/know-thy-java-object-memory-layout.html The tool jol is a library that can be used to identify the expected size of an object. Here we see the output for testing with jol on a 64bit compressed oops JVM. public final class MyClassSingleInt { public int value ; } com . bvb . MyClassSingleInt object internals : OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 ( object header ) N / A 12 4 int MyClassSingleInt . value N / A Instance size : 16 bytes Space losses : 0 bytes internal + 0 bytes external = 0 bytes total public final class MyClassTwoInts { public int int1 ; public int int2 ; } com . bvb . MyClassTwoInts object internals : OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 ( object header ) N / A 12 4 int MyClassTwoInts . int1 N / A 16 4 int MyClassTwoInts . int2 N / A 20 4 ( loss due to the next object alignment ) Instance size : 24 bytes Space losses : 0 bytes internal + 4 bytes external = 4 bytes total You can see that the second object with two ints, each of size 4 bytes, will loose a total of 4 bytes due to the alignment of the object on 8 byte boundaries. Compressed Oops \u00b6 Oops stands for ordinary object pointer and refers to the object references in the JVM. On 64bit hardware a pointer is sized at 64 bits, whereas in the 32bit world obviously 32bits. 32 bit means the addressable memory is 4GB. 64 bit means the addressable memory is 2^64 bytes, which is a lot. The use of 64bit pointers in the JVM incurs a performance penalty due to the extra data that uses up valuable space in the CPU caches. Java Performance the Definitive Guide lists the penalty as being 5-20% for moving to 64bit from 32bit. In order to get round this potential performance issue the JVM uses a trick that increases performance. It stores what is really a 35bit pointer in a 32bit memory location/register. Then when actually using this pointer it shifts it 3 places to the left. This means obviously that the first three bits are always zero for every pointer. 35 bit means the addressable memory is 32GB. As the first three places are always zero, the JVM is only able to reference memory that is divisible by 8. Objects in the 32bit and 64bit JVM are already aligned on a 8-byte boundary and therefore this additional overhead should not make any difference. Heaps <32GB use compressed oops by default since a version of Java 7. Heaps over 32GB revert to using the 64 bit pointers and therefore are most likely slower, even if the heap itself is only using (as an example) 500MB extra over 32GB. Enable remote debugging \u00b6 Java 8 and before \u00b6 -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005 Java 9+ \u00b6 -agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005 Enable JMX without auth \u00b6 Warning don't expose this to the world Commands to enable Jmx without any authentication -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=[jmx port] -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=<hostname or ip used to connect to the remote server> Sometimes it happens that the ip picked up automatically for hostname above is 127.0.0.1 and therefore when connecting remotely it will seem to connect but will then fail.","title":"JVM"},{"location":"coding/jvm/jvm/#child-pages","text":"JVM Flags JVM Troublehsooting","title":"Child pages"},{"location":"coding/jvm/jvm/#java-native-memory","text":"Stats were added in Java 8 when the permgen data was moved off heap. Enabled by setting the option: -XX:NativeMemoryTracking=off|summary|details If you enable the summary or detailed information it is then possible to capture the stats using jcmd: jcmd <pid> VM.native_memory_summary It is also possible to set a baseline and then produce a diff using jcmd Start app and capture baseline jcmd <pid> VM.native_memory baseline Then you can produce a diff jcmd <pid> VM.native_memory summary.diff You can access the detailed information using jcmd again: jcmd <pid> VM.native_memory detail","title":"Java native memory"},{"location":"coding/jvm/jvm/#java-object-layout","text":"Provides a good guide to the size of the object header in Java and what it is made up of, for 64bit (compressed oops on and off) and 32 bit JVM. https://gist.github.com/arturmkrtchyan/43d6135e8a15798cc46c Excellent guide to memory layout: http://psy-lob-saw.blogspot.com/2013/05/know-thy-java-object-memory-layout.html The tool jol is a library that can be used to identify the expected size of an object. Here we see the output for testing with jol on a 64bit compressed oops JVM. public final class MyClassSingleInt { public int value ; } com . bvb . MyClassSingleInt object internals : OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 ( object header ) N / A 12 4 int MyClassSingleInt . value N / A Instance size : 16 bytes Space losses : 0 bytes internal + 0 bytes external = 0 bytes total public final class MyClassTwoInts { public int int1 ; public int int2 ; } com . bvb . MyClassTwoInts object internals : OFFSET SIZE TYPE DESCRIPTION VALUE 0 12 ( object header ) N / A 12 4 int MyClassTwoInts . int1 N / A 16 4 int MyClassTwoInts . int2 N / A 20 4 ( loss due to the next object alignment ) Instance size : 24 bytes Space losses : 0 bytes internal + 4 bytes external = 4 bytes total You can see that the second object with two ints, each of size 4 bytes, will loose a total of 4 bytes due to the alignment of the object on 8 byte boundaries.","title":"Java object layout"},{"location":"coding/jvm/jvm/#compressed-oops","text":"Oops stands for ordinary object pointer and refers to the object references in the JVM. On 64bit hardware a pointer is sized at 64 bits, whereas in the 32bit world obviously 32bits. 32 bit means the addressable memory is 4GB. 64 bit means the addressable memory is 2^64 bytes, which is a lot. The use of 64bit pointers in the JVM incurs a performance penalty due to the extra data that uses up valuable space in the CPU caches. Java Performance the Definitive Guide lists the penalty as being 5-20% for moving to 64bit from 32bit. In order to get round this potential performance issue the JVM uses a trick that increases performance. It stores what is really a 35bit pointer in a 32bit memory location/register. Then when actually using this pointer it shifts it 3 places to the left. This means obviously that the first three bits are always zero for every pointer. 35 bit means the addressable memory is 32GB. As the first three places are always zero, the JVM is only able to reference memory that is divisible by 8. Objects in the 32bit and 64bit JVM are already aligned on a 8-byte boundary and therefore this additional overhead should not make any difference. Heaps <32GB use compressed oops by default since a version of Java 7. Heaps over 32GB revert to using the 64 bit pointers and therefore are most likely slower, even if the heap itself is only using (as an example) 500MB extra over 32GB.","title":"Compressed Oops"},{"location":"coding/jvm/jvm/#enable-remote-debugging","text":"","title":"Enable remote debugging"},{"location":"coding/jvm/jvm/#java-8-and-before","text":"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=5005","title":"Java 8 and before"},{"location":"coding/jvm/jvm/#java-9","text":"-agentlib:jdwp=transport=dt_socket,server=y,suspend=n,address=*:5005","title":"Java 9+"},{"location":"coding/jvm/jvm/#enable-jmx-without-auth","text":"Warning don't expose this to the world Commands to enable Jmx without any authentication -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=[jmx port] -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=<hostname or ip used to connect to the remote server> Sometimes it happens that the ip picked up automatically for hostname above is 127.0.0.1 and therefore when connecting remotely it will seem to connect but will then fail.","title":"Enable JMX without auth"},{"location":"coding/shell/bash-handling-params/","text":"Example script that deals with input params by name \u00b6 #!/usr/bin/env bash set -euo pipefail # pipefail # e=if a command fails the shell will exit (i.e. return > 0) # u=write an error when trying to expand a variable that is not set # o=set pipefail When used in combination with set -e, pipefail will make a script exit if any command in a pipeline errors. ## Fetching params by name rather than position INPUT = default-input.txt OUTPUT = default-output.txt while [[ ${#} -gt 0 ]] ; do case \" ${ 1 } \" in --input ) INPUT = \" ${ 2 } \" ; shift ;; --output ) OUTPUT = \" ${ 2 } \" ; shift ;; -- ) break ;; -* ) echo \"Unrecognized option ${ 1 } \" ; exit 1 ; esac shift done # Check for var being null if [[ ${ INPUT } == \"\" ]] ; then echo \"--input needs to be set\" exit 1 ; fi","title":"Bash Handling params"},{"location":"coding/shell/bash-handling-params/#example-script-that-deals-with-input-params-by-name","text":"#!/usr/bin/env bash set -euo pipefail # pipefail # e=if a command fails the shell will exit (i.e. return > 0) # u=write an error when trying to expand a variable that is not set # o=set pipefail When used in combination with set -e, pipefail will make a script exit if any command in a pipeline errors. ## Fetching params by name rather than position INPUT = default-input.txt OUTPUT = default-output.txt while [[ ${#} -gt 0 ]] ; do case \" ${ 1 } \" in --input ) INPUT = \" ${ 2 } \" ; shift ;; --output ) OUTPUT = \" ${ 2 } \" ; shift ;; -- ) break ;; -* ) echo \"Unrecognized option ${ 1 } \" ; exit 1 ; esac shift done # Check for var being null if [[ ${ INPUT } == \"\" ]] ; then echo \"--input needs to be set\" exit 1 ; fi","title":"Example script that deals with input params by name"},{"location":"coding/training/async-profiler/","text":"Async profiler with Andrei Pangin \u00b6 Source video: https://www.youtube.com/watch?v=H6glyrKQlg8&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=1 Types of profiling \u00b6 Tracing \u00b6 Usually instrumentation of bytecode Slow and therefore cannot be used for production Sampling \u00b6 Periodic snapshots of what the app is doing Lighter weight than tracing and can be used in production The sampling period will control the amount of overhead Andrei uses it in prod for their app Sampling in depth \u00b6 In Java code: Thread.getAllStackTraces() returns a Map<Thread, StackTraceElement[]> Then there is a JVMTI method with some extra information 1000 threads: 50ms latency ~10MB results size Advantages are it is simple VisualVM, YourKit Demo 1 \u00b6 VisualVM is safepoint based, therefore it shows the Thread.currentThread().isAlive() is where all the time is spent. Then he tries it with JFR and states that JMC showed nothing as it only took one sample at 10s. Safepoint \u00b6 HotSpot JVM stops all threads to take a thread dump but requires somewhere in the code to do this. Safepoints allow the JVM to take a thread dump at this point. Safepoints are usually at: End of the method Loops Long linear piece of code won't appear in the stack trace due to the fact that there is no safepoint to allow this to be captured. Native methods \u00b6 JVM has no clue when executing native method, as to whether it is sleeping or actually doing real work. Busy client versus idle client will show up at taking equal amount of time. Solving GetAllStackTraces problems \u00b6 Avoid SafePoint bias Skip idle threads Profile native code correctly AsyncGetCallTrace API \u00b6 This is an internal HotSpot API to get stack traces from current thread. Native code to call using signal handler, probably timer handler. Honest profiler and async profiler used this API is private and not documented. Compares with honest profilers against native method example above, which shows the correct values for native methods that aren't doing anything. Skips idle threads No safepoint bias Another JVM option required Important 01 \u00b6 When executing with AsyncGetCallTrace you need to specify -XX+DebugNonSafepoints -XX:+UnlockDiagnosticVMOptions as HotSpot generates debug info only at Safepoints. This means that for serveral inlined methods, without this flag then you won't see the inlined methods at all. AsyncGetCallTrace fails \u00b6 There are bugs in teh JVM that prevent this from working each time. Async profiler has introduced work arounds to traverse the stack correctly in these cases, tricks as the author called them. See https://bugs.openjdk.java.net/browse/JDK-8178287 PMU \u00b6 Starting with Pentium all chips have hardware performance monitoring. Hundreds of different counters in modern CPUs. It can be configured to generate HW interrupt when certain counter overflows. We can use this to do profiling. Counters = cycles, instructions, cache misses, branch misses Linux PMU \u00b6 perf_event_open (peo) Linux syscall, subscribe to HW/OS events peo also allows some profiling in hardware perf \u00b6 Example perf record -F 1009 java perf report Takes a sample 1009 times per second, the above is not a typo but uses a prime number rather than 1000 to avoid collision with other schedule events in the system. We don't see anything about java because perf doesn't understand Java, JIT, etc. We need to tell perf to understand the mapping perf-map-agent can collect this information to provide a mapping file for use by perf. It requires a specific flag to be set -XX:+PreserveFramePointer flag. perf uses FramePointers Each stack frame represents function or method. Base slot of each frame points to previous frame, therefore we can walk through collecting the stack trace. How to find the first frame? The JVM frame pointer register points to this, but HotSpot uses frame pointer as regular general purpose register by default. This flag reverses this optimisation, which costs <5% overhead Flamegraph \u00b6 y-axis = stack trace, higher = deeper stack Length of rectangle on x-axis = total time spent in this method. This is sampling so wouldn't be correct to state that this is time, seen more times on sampling. You can search and it states at the bottom right the number matches in terms of % times seen. Green = Java method Yellow = C++ method JVM Red = native method Brown = Linux Kernel code Problems with perf \u00b6 Perf sees interpreter as single piece of machine code, it doesn't understand what interpreted method is being executed, therefore in his example its difficult to understand what method is using the CPU. Requires special agent Requires flag to be set Needs some things set on the Linux kernel level Perf is limited by default to 127 stack frames Perf profiles are very large 1000 threads for 60s = GB output file Async Profiler part 2 \u00b6 Video: https://www.youtube.com/watch?v=WnRngFMBe7w&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=2 Mixed approach \u00b6 Good to mix approach from perf_event_open for kernel, native, use HW counters and then use the AsyncGetCallTrace API for Java. This is the method used in async profiler The tricky part is how to merge the two stacks from both sources. How to use flamegraphs \u00b6 Look for leaf flames Look for long leaf flames Using Async profiler \u00b6 You can attach later but you should use -XX:+UnlockDiagnosticVMOptions -XX+DebugNonSafepoints if you intend to do that. Demo3 \u00b6 FileReader \u00b6 He provided a number of options for buffers to use for reading a file to provide the best IO. He originally went for 32M as the buffer to use, with the thinking being that we have less system calls, etc. In the case he tested 16M was more performant than 32M. The page faults in the kernel were caused by malloc using a different implementation for the size of the allocation. In the case of 32M it involved paging but with a smaller buffer it was ok. nanoTime \u00b6 Strange behavioiur of nanoTime When is colleague upgraded his PC, all his benchmarks became much slower. The reason was nanoTime was much slower on this upgrade. There will be no difference with a Java only profiler. With async you can see that there are system calls in brown. This is related to multiple available clock sources being in Linux. I found an issue when testing with J8/J11, with and without the DebugNonSafePoints setting. Example local execution on Linux 5.4.0-58-generic : Here we see [unknown_Java] which is obviously the call to gettime. Slow time on EC2 due to clock source being XEN by default, see here: https://aws.amazon.com/premiumsupport/knowledge-center/manage-ec2-linux-clock-source/ Wall clock profiling \u00b6 Can start as an agent CPU won't always show why your startup is slow. The time is not always spent on CPU intensive work, may be disk IO, netIO (DB, etc), logs etc Wall clock profiling handles: Thread.sleep Object.wait / Condition.await Wait to get lock/semaphore Wait for IO Lock contention \u00b6 Special mode for lock contention ./profiler.sh -e lock -o flamegraph = total Counts the amount of time spent acquiring locks This applies for reentrant locks, etc flamegraph=total will then show total time in nanoseconds PAUSED at 39:00 on the second video. Async Profiler part 3 \u00b6 https://www.youtube.com/watch?v=bTDmpwhwy3E&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=3 How many objects created? \u00b6 Not always obvious how many objects are being created, even with simple code. He gives an example about timezones and alloc being out of control. The bug was the timezone was unknown and therefore it was creating its rules each time. VisualVM Sampler \u00b6 Sampler = snapshot of histogram of the objects on the heap at that point. Profiler \u00b6 Profiler = bytecode instrumentation, added to all places where new objects are allocated. More accurate but slower. They optimiste by getting sample each n times Dtrace/SystemTap \u00b6 One other method that worked for HotSpot is allocation probe. This worked in JDK8 but may not work in All allocs are slower, large overhead Other tools \u00b6 Aprof, instrumenting profiler but very optimised; https://github.com/devexperts/aprof Allocation instrumenter, actually a framework for writing your own allocation tests. https://github.com/google/allocation-instrumenter Overhead \u00b6 They have a large overhead apart from JMC. JMC \u00b6 JMC has very low overhead < 5% overhead for capturing allocation. Now OS and backported to 8u262 Gives you the stack trace to where the objects are allocated from. TLAB (Thread Local Allocation Buffer) \u00b6 If enough space in TLAB, use simple TLAB alloc If not enough space in TLAB, 2 options: Allocate directly in EDEN Or a new TLAB is allocated and the existing discarded Simple TLAB \u00b6 Fast: inlined Allocation is handled here first if possible The allocation requires no synch Alloc involves simple pointer increment Slower \u00b6 Call to VM Runtime Outside TLAB Allocation of new TLAB JFR, Async Profiler \u00b6 They are both concerned only with Flight Recorder o Tasks \u00b6 Raise issue about nanotime, even when connecting directly as agent it didn't work as expected. demo6 doesn't work as expected due to the classpath failure Second part of the presentation doesn't seem to be there Questions \u00b6 Does Async profiler rely on some Linux signals? Async profiler works with what JVMs? It works with: HotSpot, Azul (no IBM :<) YourKit supports Async traces via AsyncGetCallTrace Can you profile specific Java threads to decrease overhead Do you need sudo permissions to run Profiler? You don't need root to run the image","title":"Async profiler"},{"location":"coding/training/async-profiler/#async-profiler-with-andrei-pangin","text":"Source video: https://www.youtube.com/watch?v=H6glyrKQlg8&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=1","title":"Async profiler with Andrei Pangin"},{"location":"coding/training/async-profiler/#types-of-profiling","text":"","title":"Types of profiling"},{"location":"coding/training/async-profiler/#tracing","text":"Usually instrumentation of bytecode Slow and therefore cannot be used for production","title":"Tracing"},{"location":"coding/training/async-profiler/#sampling","text":"Periodic snapshots of what the app is doing Lighter weight than tracing and can be used in production The sampling period will control the amount of overhead Andrei uses it in prod for their app","title":"Sampling"},{"location":"coding/training/async-profiler/#sampling-in-depth","text":"In Java code: Thread.getAllStackTraces() returns a Map<Thread, StackTraceElement[]> Then there is a JVMTI method with some extra information 1000 threads: 50ms latency ~10MB results size Advantages are it is simple VisualVM, YourKit","title":"Sampling in depth"},{"location":"coding/training/async-profiler/#demo-1","text":"VisualVM is safepoint based, therefore it shows the Thread.currentThread().isAlive() is where all the time is spent. Then he tries it with JFR and states that JMC showed nothing as it only took one sample at 10s.","title":"Demo 1"},{"location":"coding/training/async-profiler/#safepoint","text":"HotSpot JVM stops all threads to take a thread dump but requires somewhere in the code to do this. Safepoints allow the JVM to take a thread dump at this point. Safepoints are usually at: End of the method Loops Long linear piece of code won't appear in the stack trace due to the fact that there is no safepoint to allow this to be captured.","title":"Safepoint"},{"location":"coding/training/async-profiler/#native-methods","text":"JVM has no clue when executing native method, as to whether it is sleeping or actually doing real work. Busy client versus idle client will show up at taking equal amount of time.","title":"Native methods"},{"location":"coding/training/async-profiler/#solving-getallstacktraces-problems","text":"Avoid SafePoint bias Skip idle threads Profile native code correctly","title":"Solving GetAllStackTraces problems"},{"location":"coding/training/async-profiler/#asyncgetcalltrace-api","text":"This is an internal HotSpot API to get stack traces from current thread. Native code to call using signal handler, probably timer handler. Honest profiler and async profiler used this API is private and not documented. Compares with honest profilers against native method example above, which shows the correct values for native methods that aren't doing anything. Skips idle threads No safepoint bias Another JVM option required","title":"AsyncGetCallTrace API"},{"location":"coding/training/async-profiler/#important-01","text":"When executing with AsyncGetCallTrace you need to specify -XX+DebugNonSafepoints -XX:+UnlockDiagnosticVMOptions as HotSpot generates debug info only at Safepoints. This means that for serveral inlined methods, without this flag then you won't see the inlined methods at all.","title":"Important 01"},{"location":"coding/training/async-profiler/#asyncgetcalltrace-fails","text":"There are bugs in teh JVM that prevent this from working each time. Async profiler has introduced work arounds to traverse the stack correctly in these cases, tricks as the author called them. See https://bugs.openjdk.java.net/browse/JDK-8178287","title":"AsyncGetCallTrace fails"},{"location":"coding/training/async-profiler/#pmu","text":"Starting with Pentium all chips have hardware performance monitoring. Hundreds of different counters in modern CPUs. It can be configured to generate HW interrupt when certain counter overflows. We can use this to do profiling. Counters = cycles, instructions, cache misses, branch misses","title":"PMU"},{"location":"coding/training/async-profiler/#linux-pmu","text":"perf_event_open (peo) Linux syscall, subscribe to HW/OS events peo also allows some profiling in hardware","title":"Linux PMU"},{"location":"coding/training/async-profiler/#perf","text":"Example perf record -F 1009 java perf report Takes a sample 1009 times per second, the above is not a typo but uses a prime number rather than 1000 to avoid collision with other schedule events in the system. We don't see anything about java because perf doesn't understand Java, JIT, etc. We need to tell perf to understand the mapping perf-map-agent can collect this information to provide a mapping file for use by perf. It requires a specific flag to be set -XX:+PreserveFramePointer flag. perf uses FramePointers Each stack frame represents function or method. Base slot of each frame points to previous frame, therefore we can walk through collecting the stack trace. How to find the first frame? The JVM frame pointer register points to this, but HotSpot uses frame pointer as regular general purpose register by default. This flag reverses this optimisation, which costs <5% overhead","title":"perf"},{"location":"coding/training/async-profiler/#flamegraph","text":"y-axis = stack trace, higher = deeper stack Length of rectangle on x-axis = total time spent in this method. This is sampling so wouldn't be correct to state that this is time, seen more times on sampling. You can search and it states at the bottom right the number matches in terms of % times seen. Green = Java method Yellow = C++ method JVM Red = native method Brown = Linux Kernel code","title":"Flamegraph"},{"location":"coding/training/async-profiler/#problems-with-perf","text":"Perf sees interpreter as single piece of machine code, it doesn't understand what interpreted method is being executed, therefore in his example its difficult to understand what method is using the CPU. Requires special agent Requires flag to be set Needs some things set on the Linux kernel level Perf is limited by default to 127 stack frames Perf profiles are very large 1000 threads for 60s = GB output file","title":"Problems with perf"},{"location":"coding/training/async-profiler/#async-profiler-part-2","text":"Video: https://www.youtube.com/watch?v=WnRngFMBe7w&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=2","title":"Async Profiler part 2"},{"location":"coding/training/async-profiler/#mixed-approach","text":"Good to mix approach from perf_event_open for kernel, native, use HW counters and then use the AsyncGetCallTrace API for Java. This is the method used in async profiler The tricky part is how to merge the two stacks from both sources.","title":"Mixed approach"},{"location":"coding/training/async-profiler/#how-to-use-flamegraphs","text":"Look for leaf flames Look for long leaf flames","title":"How to use flamegraphs"},{"location":"coding/training/async-profiler/#using-async-profiler","text":"You can attach later but you should use -XX:+UnlockDiagnosticVMOptions -XX+DebugNonSafepoints if you intend to do that.","title":"Using Async profiler"},{"location":"coding/training/async-profiler/#demo3","text":"","title":"Demo3"},{"location":"coding/training/async-profiler/#filereader","text":"He provided a number of options for buffers to use for reading a file to provide the best IO. He originally went for 32M as the buffer to use, with the thinking being that we have less system calls, etc. In the case he tested 16M was more performant than 32M. The page faults in the kernel were caused by malloc using a different implementation for the size of the allocation. In the case of 32M it involved paging but with a smaller buffer it was ok.","title":"FileReader"},{"location":"coding/training/async-profiler/#nanotime","text":"Strange behavioiur of nanoTime When is colleague upgraded his PC, all his benchmarks became much slower. The reason was nanoTime was much slower on this upgrade. There will be no difference with a Java only profiler. With async you can see that there are system calls in brown. This is related to multiple available clock sources being in Linux. I found an issue when testing with J8/J11, with and without the DebugNonSafePoints setting. Example local execution on Linux 5.4.0-58-generic : Here we see [unknown_Java] which is obviously the call to gettime. Slow time on EC2 due to clock source being XEN by default, see here: https://aws.amazon.com/premiumsupport/knowledge-center/manage-ec2-linux-clock-source/","title":"nanoTime"},{"location":"coding/training/async-profiler/#wall-clock-profiling","text":"Can start as an agent CPU won't always show why your startup is slow. The time is not always spent on CPU intensive work, may be disk IO, netIO (DB, etc), logs etc Wall clock profiling handles: Thread.sleep Object.wait / Condition.await Wait to get lock/semaphore Wait for IO","title":"Wall clock profiling"},{"location":"coding/training/async-profiler/#lock-contention","text":"Special mode for lock contention ./profiler.sh -e lock -o flamegraph = total Counts the amount of time spent acquiring locks This applies for reentrant locks, etc flamegraph=total will then show total time in nanoseconds PAUSED at 39:00 on the second video.","title":"Lock contention"},{"location":"coding/training/async-profiler/#async-profiler-part-3","text":"https://www.youtube.com/watch?v=bTDmpwhwy3E&list=PLNCLTEx3B8h4Yo_WvKWdLvI9mj1XpTKBr&index=3","title":"Async Profiler part 3"},{"location":"coding/training/async-profiler/#how-many-objects-created","text":"Not always obvious how many objects are being created, even with simple code. He gives an example about timezones and alloc being out of control. The bug was the timezone was unknown and therefore it was creating its rules each time.","title":"How many objects created?"},{"location":"coding/training/async-profiler/#visualvm-sampler","text":"Sampler = snapshot of histogram of the objects on the heap at that point.","title":"VisualVM Sampler"},{"location":"coding/training/async-profiler/#profiler","text":"Profiler = bytecode instrumentation, added to all places where new objects are allocated. More accurate but slower. They optimiste by getting sample each n times","title":"Profiler"},{"location":"coding/training/async-profiler/#dtracesystemtap","text":"One other method that worked for HotSpot is allocation probe. This worked in JDK8 but may not work in All allocs are slower, large overhead","title":"Dtrace/SystemTap"},{"location":"coding/training/async-profiler/#other-tools","text":"Aprof, instrumenting profiler but very optimised; https://github.com/devexperts/aprof Allocation instrumenter, actually a framework for writing your own allocation tests. https://github.com/google/allocation-instrumenter","title":"Other tools"},{"location":"coding/training/async-profiler/#overhead","text":"They have a large overhead apart from JMC.","title":"Overhead"},{"location":"coding/training/async-profiler/#jmc","text":"JMC has very low overhead < 5% overhead for capturing allocation. Now OS and backported to 8u262 Gives you the stack trace to where the objects are allocated from.","title":"JMC"},{"location":"coding/training/async-profiler/#tlab-thread-local-allocation-buffer","text":"If enough space in TLAB, use simple TLAB alloc If not enough space in TLAB, 2 options: Allocate directly in EDEN Or a new TLAB is allocated and the existing discarded","title":"TLAB (Thread Local Allocation Buffer)"},{"location":"coding/training/async-profiler/#simple-tlab","text":"Fast: inlined Allocation is handled here first if possible The allocation requires no synch Alloc involves simple pointer increment","title":"Simple TLAB"},{"location":"coding/training/async-profiler/#slower","text":"Call to VM Runtime Outside TLAB Allocation of new TLAB","title":"Slower"},{"location":"coding/training/async-profiler/#jfr-async-profiler","text":"They are both concerned only with Flight Recorder o","title":"JFR, Async Profiler"},{"location":"coding/training/async-profiler/#tasks","text":"Raise issue about nanotime, even when connecting directly as agent it didn't work as expected. demo6 doesn't work as expected due to the classpath failure Second part of the presentation doesn't seem to be there","title":"Tasks"},{"location":"coding/training/async-profiler/#questions","text":"Does Async profiler rely on some Linux signals? Async profiler works with what JVMs? It works with: HotSpot, Azul (no IBM :<) YourKit supports Async traces via AsyncGetCallTrace Can you profile specific Java threads to decrease overhead Do you need sudo permissions to run Profiler? You don't need root to run the image","title":"Questions"},{"location":"linux/monitoring/","text":"Linux Monitoring \u00b6 Memory \u00b6 free -m List of availble memory and used memory before/after buffers and caches are taken into consideration. Does not include the memory used for the kernel caches, i.e. Slab. This memory will contribute to the overall used memory but will not show against the process. Show resident set size (RSS) and virtual memory size (VMZ) for processes, also lists the command. ps -eo pid,rss,vsz,cmd If you take the sum of RSS + Slab -Shared then it is roughly equivalent to used memory from free (-buffers, caches). List the current memory usage with breakdowns: cat /proc/meminfo List the slab usage cat /proc/slabinfo For the above the size (Bytes) can be calculated by multiplying <num_objs> * <objsize> . Also slabtop provides info on the used memory for slab. slabtop References \u00b6 Droping kernel caches: https://linux-mm.org/Drop_Caches Where is my memory: https://www.dedoimedo.com/computers/slabinfo.html Redhat6 memory info: https://access.redhat.com/solutions/406773 Slabs: https://medium.com/@dhelios/memory-caches-and-slab-objects-c1de113ce235 pidstat \u00b6 Show stats for a particular process including voluntary and non-volunatary context switches pidstat -w -p <pid> <interval secs> e.g. pidstat -w -p 1345 1 strace \u00b6 Capture system calls for app strace -c -f -p <pid> -c = capture count -f = trace child processes To exit after a specific time period timeout <secs> strace -c -f -p <pid> count threads \u00b6 Count the number of threads for a process cat /proc/<pid>/status There is the list is threads or cat /proc/<pid>/status | grep -i threads disk io latency \u00b6 iostat -dxt 1 sdb","title":"Monitoring"},{"location":"linux/monitoring/#linux-monitoring","text":"","title":"Linux Monitoring"},{"location":"linux/monitoring/#memory","text":"free -m List of availble memory and used memory before/after buffers and caches are taken into consideration. Does not include the memory used for the kernel caches, i.e. Slab. This memory will contribute to the overall used memory but will not show against the process. Show resident set size (RSS) and virtual memory size (VMZ) for processes, also lists the command. ps -eo pid,rss,vsz,cmd If you take the sum of RSS + Slab -Shared then it is roughly equivalent to used memory from free (-buffers, caches). List the current memory usage with breakdowns: cat /proc/meminfo List the slab usage cat /proc/slabinfo For the above the size (Bytes) can be calculated by multiplying <num_objs> * <objsize> . Also slabtop provides info on the used memory for slab. slabtop","title":"Memory"},{"location":"linux/monitoring/#references","text":"Droping kernel caches: https://linux-mm.org/Drop_Caches Where is my memory: https://www.dedoimedo.com/computers/slabinfo.html Redhat6 memory info: https://access.redhat.com/solutions/406773 Slabs: https://medium.com/@dhelios/memory-caches-and-slab-objects-c1de113ce235","title":"References"},{"location":"linux/monitoring/#pidstat","text":"Show stats for a particular process including voluntary and non-volunatary context switches pidstat -w -p <pid> <interval secs> e.g. pidstat -w -p 1345 1","title":"pidstat"},{"location":"linux/monitoring/#strace","text":"Capture system calls for app strace -c -f -p <pid> -c = capture count -f = trace child processes To exit after a specific time period timeout <secs> strace -c -f -p <pid>","title":"strace"},{"location":"linux/monitoring/#count-threads","text":"Count the number of threads for a process cat /proc/<pid>/status There is the list is threads or cat /proc/<pid>/status | grep -i threads","title":"count threads"},{"location":"linux/monitoring/#disk-io-latency","text":"iostat -dxt 1 sdb","title":"disk io latency"}]}